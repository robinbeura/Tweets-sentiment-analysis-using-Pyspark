{
 "cells": [
  {
   "source": [
    "# Tweets sentiment analysis using Pyspark\n",
    "## The sentiment scores are assigned using Bing Liu opinion lexicon"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "### API to query for #hospital and get atleast 1000 tweets\n",
    "\n",
    "import time\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "access_key = '1314619141517701126-XLK51FotjzkViLWCavDAK3bQScy5Gp'\n",
    "access_secret = 'tR25RRQoIj6h8T4eGSU0EyJTN5CJ97MEccEZkqzydAS5p'\n",
    "consumer_key = 'Y5PySZEtOGePMEmCy2LgfDe5P'\n",
    "consumer_secret = 'RJ1OttT9CiFPWwdQfhc2Uzscjcpg5pEdcJotEgAxZlb6aK1wjU'\n",
    "\n",
    "#auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_key, access_secret)\n",
    "#twitterStream=Stream(auth,listener())\n",
    "#twitterStream.filter(track=[\"#hospital\"])\n",
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "query = '#hospital'\n",
    "max_tweets = 2500\n",
    "searched_tweets = [status for status in tweepy.Cursor(api.search, q=query).items(max_tweets)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Checking number of tweets\n",
    "len(searched_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_tweets = []\n",
    "for tweets in searched_tweets:\n",
    "    hospital_tweets.append(tweets.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "rdd = sc.parallelize(hospital_tweets)\n",
    "row_rdd = rdd.map(lambda x: Row(x))\n",
    "\n",
    "#### Tweets dataframe\n",
    "spark_df=sqlContext.createDataFrame(row_rdd,['Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Removing punctuation, special characters and numbers\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F \n",
    "spark_df = spark_df.withColumn(\"Tweet_content\", F.regexp_replace(spark_df.Tweets, r\"[^a-zA-Z\\. ]\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              Tweets|       Tweet_content|\n",
      "+--------------------+--------------------+\n",
      "|RT @SeufertRecht:...|RT SeufertRecht S...|\n",
      "|RT @SeufertRecht:...|RT SeufertRecht S...|\n",
      "|#Corona #COVID19 ...|Corona COVID COVI...|\n",
      "|Durga Puja\n",
      "#durga...|Durga Pujadurgapu...|\n",
      "|Breaking News: 24...|Breaking News Oct...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating user-defined function to check the language\n",
    "from langdetect import detect\n",
    "from pyspark.sql.functions import udf, lit\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def check_lang(data_str):\n",
    "    predict_lang = detect(data_str)\n",
    "    if predict_lang == 'en':\n",
    "        language = predict_lang\n",
    "    else:\n",
    "        language = 'NA'\n",
    "    return language    \n",
    "check_lang_udf = udf(check_lang, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Only kept the english language for accurate sentiment score detection\n",
    "\n",
    "spark_df = spark_df.withColumn(\"Language\", check_lang_udf(spark_df['Tweet_content']))\n",
    "spark_df = spark_df.filter(spark_df.Language == 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1766"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.count()   ##### to ensure atleast 1000 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+\n",
      "|              Tweets|       Tweet_content|Language|\n",
      "+--------------------+--------------------+--------+\n",
      "|RT @SeufertRecht:...|RT SeufertRecht S...|      en|\n",
      "|RT @SeufertRecht:...|RT SeufertRecht S...|      en|\n",
      "|#Corona #COVID19 ...|Corona COVID COVI...|      en|\n",
      "|Breaking News: 24...|Breaking News Oct...|      en|\n",
      "|41 million adults...| million adults i...|      en|\n",
      "+--------------------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tokenizer object\n",
    "tokenizer = RegexTokenizer().setInputCol('Tweet_content').setOutputCol('words')\n",
    "#### Regex tokenizer first converts the words to lower space and then splits by white-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df = tokenizer.transform(spark_df)#.select('tweets_new','words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|       Tweet_content|        word|\n",
      "+--------------------+------------+\n",
      "|RT SeufertRecht S...|          rt|\n",
      "|RT SeufertRecht S...|seufertrecht|\n",
      "|RT SeufertRecht S...|     seufert|\n",
      "|RT SeufertRecht S...|     advises|\n",
      "|RT SeufertRecht S...|       peine|\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### checking dataset into tall format\n",
    "\n",
    "hospital_df.select('Tweet_content', F.explode('words').alias('word')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|     word|sentiment|\n",
      "+---------+---------+\n",
      "|       a+|        1|\n",
      "|   abound|        1|\n",
      "|  abounds|        1|\n",
      "|abundance|        1|\n",
      "| abundant|        1|\n",
      "+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######### Downlaod Bing Liu opinion lexicon files \n",
    "\n",
    "### negative words\n",
    "neg=sc.textFile(\"C:\\\\Users\\\\rahul\\\\Documents\\\\big_data\\\\opinion-lexicon-English\\\\opinion-lexicon-English\\\\negative-words.txt\")\n",
    "temp_var = neg.map(lambda k: k.split(\"\\\\t\"))\n",
    "neg_df = temp_var.toDF()\n",
    "neg_df= neg_df.withColumn('sentiment',lit(-1))\n",
    "\n",
    "### positive words\n",
    "pos=sc.textFile(\"C:\\\\Users\\\\rahul\\\\Documents\\\\big_data\\\\opinion-lexicon-English\\\\opinion-lexicon-English\\\\positive-words.txt\")\n",
    "temp_var_pos = pos.map(lambda k: k.split(\"\\\\t\"))\n",
    "pos_df = temp_var_pos.toDF()\n",
    "pos_df= pos_df.withColumn('sentiment',lit(1))\n",
    "\n",
    "#### concat both\n",
    "words_concat = pos_df.union(neg_df)\n",
    "columns = ['word','sentiment']\n",
    "words = words_concat.toDF(*columns)\n",
    "words.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---------+\n",
      "|        word|       Tweet_content|sentiment|\n",
      "+------------+--------------------+---------+\n",
      "|inflammatory|RT frhossain Infl...|       -1|\n",
      "|    randomly|RT kellyarchives ...|       -1|\n",
      "|    randomly|RT kellyarchives ...|       -1|\n",
      "|    randomly|octors randomly r...|       -1|\n",
      "|    positive|Does the hospital...|        1|\n",
      "|    positive|Name  Ganta Guru ...|        1|\n",
      "|    positive|RT SaraECores My ...|        1|\n",
      "|    positive|My dad is a surge...|        1|\n",
      "|  productive|Sthule syabuka nj...|        1|\n",
      "|      speedy|Ranveer singh has...|        1|\n",
      "+------------+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####### joining hospital tweets with Liu Bing words to get sentiment of each word\n",
    "\n",
    "join_df = hospital_df.\\\n",
    "    select('Tweet_content', F.explode('words').alias('word')).\\\n",
    "    join(words, 'word')\n",
    "join_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|       Tweet_content|Sentiment_score|\n",
      "+--------------------+---------------+\n",
      "|RT HumanityFirstU...|             48|\n",
      "|RT CTVNews An yea...|             24|\n",
      "|RT DrNinaRadcliff...|              9|\n",
      "|RT paulbami Dwell...|              9|\n",
      "|RT CleveClinicFL ...|              8|\n",
      "+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####### Grouping sentiments by tweets and using sum of the sentiments as score\n",
    "score_df = join_df.\\\n",
    "    groupBy('Tweet_content').\\\n",
    "    agg(F.sum('sentiment').alias('Sentiment_score'))\n",
    "\n",
    "score_df.sort(col('Sentiment_score').desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Using original tweets instead of cleaned tweets in results\n",
    "final_tweets = hospital_df.\\\n",
    "    select('Tweets','Tweet_content').\\\n",
    "    join(score_df, 'Tweet_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|Tweets                                                                                                                                          |Sentiment_score|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "|RT @HumanityFirstUK: üè• Work is well underway for the Brand New #Hospital being built in Yopougon, south of C√¥te d‚ÄôIvoire #IvoryCoast\n",
      "\n",
      "You c‚Ä¶   |48             |\n",
      "|RT @CTVNews: An 81-year-old COVID-19 patient in Australia was discharged after 214 days in hospital. #ctvnews #coronavirus #pandemic #covid‚Ä¶    |24             |\n",
      "|RT @paulbami: Dwellers around #NEPA, #SIJUADE, #ESO, #HOSPITAL ROAD, LETS MEET @NEPA to clean that road by 7:00am\n",
      "What do you think?\n",
      "@iam_h‚Ä¶    |9              |\n",
      "|RT @DrNinaRadcliff: Happiest of #birthdays #angel. 9 years ago today at this time I was up &amp; ready 2 go to the #hospital 2 finally meet you‚Ä¶|9              |\n",
      "|RT @CleveClinicFL: #CleveClinicFL is more than just the a top #hospital in South Florida. @USNews also ranked us among the best hospitals i‚Ä¶    |8              |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_tweets.select('Tweets','Sentiment_score').distinct().sort(col('Sentiment_score').desc()).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df=final_tweets.select('Tweets','Sentiment_score').distinct().sort(col('Sentiment_score').desc())   ### desired output csv asked\n",
    "\n",
    "###### Saving in csv\n",
    "write_df.coalesce(1).write.csv('final_sentiments',header = 'true')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}